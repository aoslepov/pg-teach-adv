Разворачиваем ВМ в яндекс облаке
```
yc compute instance create \
  --name pg-teach-01 \
  --hostname pg-teach-01 \
  --create-boot-disk size=50G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 4 \
  --memory 8G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```

#### заливка данных в postgres

Устанавливаем postgres
```
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt-get update
sudo apt-get -y install postgresql-15
```


Настраиваем в postgres.auto.conf конфиг перед заливкой и перегружаем экземпляр
```
transaction_isolation = 'read uncommitted'
default_transaction_isolation = 'read uncommitted'
wal_level = minimal
max_wal_senders = 0
max_wal_size = '10 GB'
min_wal_size = '512 MB'
fsync = off
full_page_writes=off
checkpoint_timeout = '15 min'
checkpoint_completion_target = 0.9
wal_compression = off
synchronous_commit = off
max_worker_processes = 4
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 4
parallel_leader_participation = on
autovacuum = off
shared_buffers = '2730 MB'
work_mem = '38 MB'
maintenance_work_mem = '409 MB'
effective_cache_size = '6553 MB'
effective_io_concurrency = 200
random_page_cost = 1.2

```



Создаём таблицу
```
create  table chicago_taxi (
taxi_id bigint,
trip_start_timestamp TIMESTAMP,
trip_end_timestamp TIMESTAMP,
trip_seconds bigint,
trip_miles numeric,
pickup_census_tract bigint,
dropoff_census_tract bigint,
pickup_community_area bigint,
dropoff_community_area bigint,
fare numeric,
tips numeric,
tolls numeric,
extras numeric,
trip_total numeric,
payment_type text,
company text,
pickup_latitude numeric,
pickup_longitude numeric,
dropoff_latitude numeric,
dropoff_longitude numeric
);
```


Скрипт для заливки будем запускать 2 раза для заливки ~12GB данных
```
for i in $(ls -1 /tmp/load/chicago*.csv); do
        echo $i
        psql -d postgres -c "
BEGIN;
COPY chicago_taxi(taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,dropoff_latitude,dropoff_longitude)
FROM '$i'
DELIMITER ','
CSV HEADER;
commit; " &
done
```

Мониторим заливку
```
postgres=# select * from pg_stat_progress_copy;
 pid  | datid | datname  | relid |  command  | type | bytes_processed | bytes_total | tuples_processed | tuples_excluded
------+-------+----------+-------+-----------+------+-----------------+-------------+------------------+-----------------
 5744 |     5 | postgres | 16388 | COPY FROM | FILE |        19791872 |   210509642 |           181347 |               0
 5743 |     5 | postgres | 16388 | COPY FROM | FILE |        21692416 |   189657705 |           199827 |               0
 5745 |     5 | postgres | 16388 | COPY FROM | FILE |        21168128 |   184423109 |           195655 |               0
 5746 |     5 | postgres | 16388 | COPY FROM | FILE |        22609920 |   142068451 |           205705 |               0
 5747 |     5 | postgres | 16388 | COPY FROM | FILE |        23134208 |   214139224 |           213094 |               0
 5748 |     5 | postgres | 16388 | COPY FROM | FILE |        21561344 |   190262071 |           197280 |               0
 5754 |     5 | postgres | 16388 | COPY FROM | FILE |        23396352 |   144370403 |           209542 |               0
 5749 |     5 | postgres | 16388 | COPY FROM | FILE |        19595264 |   211196193 |           180278 |               0
 5750 |     5 | postgres | 16388 | COPY FROM | FILE |        22151168 |   138280907 |           199386 |               0
 5752 |     5 | postgres | 16388 | COPY FROM | FILE |        22544384 |   211736753 |           207410 |               0
 5753 |     5 | postgres | 16388 | COPY FROM | FILE |        22740992 |   167544420 |           203037 |               0
 5751 |     5 | postgres | 16388 | COPY FROM | FILE |        21889024 |   166738011 |           199657 |               0
 ```


Время заливки ~ 8мин

После заливки запускаем вакуум аналайз и создаём индексы
```
vacuum analyze chicago_taxi;
create index idx_taxi_id on chicago_taxi(taxi_id);
create index idx_dates on chicago_taxi(trip_start_timestamp,trip_end_timestamp);
```

Оставляем в postgres.auto.conf следующие записи и перегружаем инстанс постгрес
```
checkpoint_timeout = '15 min'
checkpoint_completion_target = 0.9
max_worker_processes = 4
max_parallel_workers_per_gather = 4
max_parallel_maintenance_workers = 4
max_parallel_workers = 4
parallel_leader_participation = on
shared_buffers = '2730 MB'
work_mem = '38 MB'
maintenance_work_mem = '409 MB'
effective_cache_size = '6553 MB'
effective_io_concurrency = 200
random_page_cost = 1.2
```


Смотрим время выполнения запросов
```

-- выборка рандомной записи по индексу
select taxi_id from chicago_taxi order by random() limit 1;
Time: 5949.964 ms (00:05.950)


--выборка данных за неделю
postgres=# select taxi_id,trip_start_timestamp,trip_end_timestamp from chicago_taxi where trip_start_timestamp between date'2016-02-01' and date'2016-02-07';
Time: 69201.562 ms (01:09.202)


postgres=# select count(*) from chicago_taxi;
  count
----------
 39732314

```


pg_dump --schema-only postgres -t chicago_taxi > /var/lib/postgresql/chicago_taxi-schema.sql

psql postgres -c "COPY chicago_taxi TO stdout DELIMITER ',' CSV;" > /var/lib/postgresql/chicago_taxi_migrate.



============

 Разворачиваем 3 ноды cockroachdb в разных зонах

 ```


 yc compute instance create \
   --name cdb-01 \
   --hostname cdb-01 \
   --create-boot-disk size=30G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
   --cores 4 \
   --memory 8G \
   --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
   --zone ru-central1-a \
   --metadata-from-file ssh-keys=/home/aslepov/meta.txt


 yc compute instance create \
    --name cdb-02 \
    --hostname cdb-02 \
    --create-boot-disk size=30G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
    --cores 4 \
    --memory 8G \
    --network-interface subnet-name=default-ru-central1-b,nat-ip-version=ipv4 \
    --zone ru-central1-b \
    --metadata-from-file ssh-keys=/home/aslepov/meta.txt

yc compute instance create \
   --name cdb-03 \
   --hostname cdb-03 \
   --create-boot-disk size=30G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
   --cores 4 \
   --memory 8G \
   --network-interface subnet-name=default-ru-central1-c,nat-ip-version=ipv4 \
   --zone ru-central1-c \
   --metadata-from-file ssh-keys=/home/aslepov/meta.txt



 ```



for i in {'62.84.117.81','84.252.141.37','51.250.47.60'}; do
ssh ubuntu@$i 'wget -qO- https://binaries.cockroachdb.com/cockroach-v21.1.6.linux-amd64.tgz -O /tmp/cockroach.tgz && sudo tar -xzvf /tmp/cockroach.tgz -C /opt && sudo mv /opt/cockroach-v21.1.6.linux-amd64 /opt/cockroach '
ssh ubuntu@$i 'sudo mkdir /opt/cockroach/{certs,my-safe-directory}'
done


cdb-01 >>
cd /opt/cockroach/
./cockroach cert create-ca --certs-dir=certs --ca-key=my-safe-directory/ca.key
./cockroach cert create-node localhost cdb-01 cdb-02 cdb-03 --certs-dir=certs --ca-key=my-safe-directory/ca.key --overwrite
./cockroach cert create-client root --certs-dir=certs --ca-key=my-safe-directory/ca.key

переносим /opt/cockroach/certs на cdb-02 и cdb-03


cdb-01>>
cd /opt/cockroach/


root@cdb-01:/opt/cockroach# ./cockroach cert list --certs-dir=certs
Certificate directory: certs
  Usage  | Certificate File |    Key File     |  Expires   |                   Notes                   | Error
---------+------------------+-----------------+------------+-------------------------------------------+--------
  CA     | ca.crt           |                 | 2033/11/02 | num certs: 1                              |
  Node   | node.crt         | node.key        | 2028/10/29 | addresses: localhost,cdb-01,cdb-02,cdb-03 |
  Client | client.root.crt  | client.root.key | 2028/10/29 | user: root                                |
(3 rows)

root@cdb-01:/opt/cockroach# ./cockroach start --certs-dir=certs --advertise-addr=cdb-01 --join=cdb-01,cdb-02,cdb-03 --cache=.25 --max-sql-memory=.25 --background
*
* INFO: initial startup completed.
* Node will now attempt to join a running cluster, or wait for `cockroach init`.
* Client connections will be accepted after this completes successfully.
* Check the log file(s) for progres




cdb-02>>
root@cdb-02:/opt/cockroach# cd /opt/cockroach/
root@cdb-02:/opt/cockroach# ./cockroach cert list --certs-dir=certs
Certificate directory: certs
  Usage  | Certificate File |    Key File     |  Expires   |                   Notes                   | Error
---------+------------------+-----------------+------------+-------------------------------------------+--------
  CA     | ca.crt           |                 | 2033/11/02 | num certs: 1                              |
  Node   | node.crt         | node.key        | 2028/10/29 | addresses: localhost,cdb-01,cdb-02,cdb-03 |
  Client | client.root.crt  | client.root.key | 2028/10/29 | user: root                                |
(3 rows)
root@cdb-02:/opt/cockroach# ./cockroach start --certs-dir=certs --advertise-addr=cdb-02 --join=cdb-01,cdb-02,cdb-03 --cache=.25 --max-sql-memory=.25 --background
*
* INFO: initial startup completed.
* Node will now attempt to join a running cluster, or wait for `cockroach init`.
* Client connections will be accepted after this completes successfully.
* Check the log file(s) for progress


cdb-03
root@cdb-03:/home/ubuntu/cdb# cd /opt/cockroach/
root@cdb-03:/opt/cockroach# ./cockroach cert list --certs-dir=certs
Certificate directory: certs
  Usage  | Certificate File |    Key File     |  Expires   |                   Notes                   | Error
---------+------------------+-----------------+------------+-------------------------------------------+--------
  CA     | ca.crt           |                 | 2033/11/02 | num certs: 1                              |
  Node   | node.crt         | node.key        | 2028/10/29 | addresses: localhost,cdb-01,cdb-02,cdb-03 |
  Client | client.root.crt  | client.root.key | 2028/10/29 | user: root                                |
(3 rows)
root@cdb-03:/opt/cockroach# ./cockroach start --certs-dir=certs --advertise-addr=cdb-03 --join=cdb-01,cdb-02,cdb-03 --cache=.25 --max-sql-memory=.25 --background
*
* INFO: initial startup completed.
* Node will now attempt to join a running cluster, or wait for `cockroach init`.
* Client connections will be accepted after this completes successfully.
* Check the log file(s) for progress.
*


cdb-01>>

root@cdb-01:/opt/cockroach# ./cockroach init --certs-dir=certs --host=cdb-01
Cluster successfully initialized
root@cdb-01:/opt/cockroach# ./cockroach node status --certs-dir=certs
  id |   address    | sql_address  |  build  |         started_at         |         updated_at         | locality | is_available | is_live
-----+--------------+--------------+---------+----------------------------+----------------------------+----------+--------------+----------
   1 | cdb-01:26257 | cdb-01:26257 | v21.1.6 | 2023-10-26 20:21:44.682438 | 2023-10-26 20:22:16.213905 |          | true         | true
   2 | cdb-03:26257 | cdb-03:26257 | v21.1.6 | 2023-10-26 20:21:45.390704 | 2023-10-26 20:22:16.907459 |          | true         | true
   3 | cdb-02:26257 | cdb-02:26257 | v21.1.6 | 2023-10-26 20:21:45.539724 | 2023-10-26 20:22:17.070153 |          | true         | true
(3 rows)


./cockroach sql --certs-dir=certs

CREATE TABLE chicago_taxi (
    taxi_id bigint,
    trip_start_timestamp timestamp without time zone,
    trip_end_timestamp timestamp without time zone,
    trip_seconds bigint,
    trip_miles numeric,
    pickup_census_tract bigint,
    dropoff_census_tract bigint,
    pickup_community_area bigint,
    dropoff_community_area bigint,
    fare numeric,
    tips numeric,
    tolls numeric,
    extras numeric,
    trip_total numeric,
    payment_type text,
    company text,
    pickup_latitude numeric,
    pickup_longitude numeric,
    dropoff_latitude numeric,
    dropoff_longitude numeric
);


 ./cockroach userfile upload --certs-dir=certs  /home/ubuntu/chicago_taxi_migrate.csv
 successfully uploaded to userfile://defaultdb.public.userfiles_root/chicago_taxi_migrate.csv
 ./cockroach userfile list '*.csv' --certs-dir=certs
./cockroach sql --certs-dir=certs
IMPORT INTO chicago_taxi CSV DATA ('userfile:///chicago_taxi_migrate.csv')  WITH nullif = '';
        job_id       |  status   | fraction_completed |   rows   | index_entries |   bytes
---------------------+-----------+--------------------+----------+---------------+-------------
  911892786404130817 | succeeded |                  1 | 39732314 |             0 | 1488393715
(1 row)

Time: 273.525s total (execution 273.525s / network 0.000s)


CREATE INDEX ON chicago_taxi (taxi_id);
CREATE INDEX ON chicago_taxi (trip_start_timestamp,trip_end_timestamp);

Смотрим время выполнения запросов
```
-- выборка рандомной записи по индексу
select taxi_id from chicago_taxi order by random() limit 1;
Time: 4.309s total (execution 4.309s / network 0.000s)

--выборка данных за неделю
postgres=# select taxi_id,trip_start_timestamp,trip_end_timestamp from chicago_taxi where trip_start_timestamp between date'2016-02-01' and date'2016-02-07';
Time: 2.794s total (execution 2.590s / network 0.204s)
```
