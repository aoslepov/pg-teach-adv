
## Домашнее задание. Развернуть HA кластер
  
### Цель: 
* развернуть высокодоступный кластер PostgeSQL собственными силами  
* развернуть высокодоступный сервис на базе PostgeSQL на базе одного из 3-ки ведущих облачных провайдеров - AWS, GCP и Azure  


### Вариант 2  
* Introducing [pg_auto_failover](https://github.com/aoslepov/pg-teach-adv/blob/main/lesson11/dz-11.md#pg_auto_failover): Open source extension for automated  failover and high-availability in PostgreSQL  
* [Задание повышенной сложности](https://github.com/aoslepov/pg-teach-adv/blob/main/lesson11/dz-11.md#%D0%B7%D0%B0%D0%B4%D0%B0%D0%BD%D0%B8%D0%B5-%D0%BF%D0%BE%D0%B2%D1%8B%D1%88%D0%B5%D0%BD%D0%BD%D0%BE%D0%B9-%D1%81%D0%BB%D0%BE%D0%B6%D0%BD%D0%BE%D1%81%D1%82%D0%B8)
  
### PG_AUTO_FAILOVER
#### Создаём вм pg-mon для монитора

```
yc compute instance create \
  --name pg-mon \
  --hostname pg-mon \
  --create-boot-disk size=10G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```


Устанавливаем pg-auto-failover, удаляем текущий инстанс
```
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt-get update

sudo apt-get install postgresql-15-auto-failover
sudo su postgres -c 'pg_dropcluster 15 main --stop'
```



Инициализаруем каталог для ноды monitor

```
sudo su - postgres
export PATH="$PATH:/usr/lib/postgresql/15/bin/"

postgres@pg-mon:~$ pg_autoctl create monitor  --pgdata ./monitor  --pgport 6000  --hostname $(hostname -I) --auth trust   --no-ssl -v

14:51:31 8259 WARN  No encryption is used for network traffic! This allows an attacker on the network to read all replication data.
14:51:31 8259 WARN  Using --ssl-self-signed instead of --no-ssl is recommend to achieve more security with the same ease of deployment.
14:51:31 8259 WARN  See https://www.postgresql.org/docs/current/libpq-ssl.html for details on how to improve
14:51:31 8259 INFO  Using default --ssl-mode "prefer"
14:51:31 8259 INFO  Initialising a PostgreSQL cluster at "./monitor"
14:51:31 8259 INFO  /usr/lib/postgresql/15/bin/pg_ctl initdb -s -D ./monitor --option '--auth=trust'
14:51:34 8259 INFO  Started pg_autoctl postgres service with pid 8278
14:51:34 8278 INFO   /usr/bin/pg_autoctl do service postgres --pgdata ./monitor -v
14:51:34 8259 INFO  Started pg_autoctl monitor-init service with pid 8279
14:51:34 8284 INFO   /usr/lib/postgresql/15/bin/postgres -D /var/lib/postgresql/monitor -p 6000 -h *
14:51:34 8278 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/monitor" on port 6000 with pid 8284
14:51:34 8279 WARN  NOTICE:  installing required extension "btree_gist"
14:51:34 8279 INFO  Granting connection privileges on 10.128.0.0/24
14:51:34 8279 WARN  Skipping HBA edits (per --skip-pg-hba) for rule: host "pg_auto_failover" "autoctl_node" 10.128.0.0/24 trust
14:51:34 8279 INFO  Your pg_auto_failover monitor instance is now ready on port 6000.
14:51:34 8279 INFO  Monitor has been successfully initialized.
14:51:34 8259 WARN  pg_autoctl service monitor-init exited with exit status 0
14:51:34 8278 INFO  Postgres controller service received signal SIGTERM, terminating
14:51:34 8278 INFO  Stopping pg_autoctl postgres service
14:51:34 8278 INFO  /usr/lib/postgresql/15/bin/pg_ctl --pgdata /var/lib/postgresql/monitor --wait stop --mode fast
14:51:34 8259 INFO  Waiting for subprocesses to terminate.
14:51:35 8259 INFO  Stop pg_autoctl
```

Добавляем доступы
```
echo 'host    replication     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/monitor/pg_hba.conf
echo 'host    all     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/monitor/pg_hba.conf
```


Смотрим настройки для сервиса и заводим его
```
postgres@pg-mon:~$ pg_autoctl show systemd --pgdata /var/lib/postgresql/monitor
14:54:07 8399 INFO  HINT: to complete a systemd integration, run the following commands (as root):
14:54:07 8399 INFO  pg_autoctl -q show systemd --pgdata "/var/lib/postgresql/monitor" | tee /etc/systemd/system/pgautofailover.service
14:54:07 8399 INFO  systemctl daemon-reload
14:54:07 8399 INFO  systemctl enable pgautofailover
14:54:07 8399 INFO  systemctl start pgautofailover
[Unit]
Description = pg_auto_failover

[Service]
WorkingDirectory = /var/lib/postgresql
Environment = 'PGDATA=/var/lib/postgresql/monitor'
User = postgres
ExecStart = /usr/bin/pg_autoctl run
Restart = always
StartLimitBurst = 0
ExecReload = /usr/bin/pg_autoctl reload

[Install]
WantedBy = multi-user.target
```


#### Создаём ноду для мастера pg-teach-01

```
yc compute instance create \
  --name pg-teach-01 \
  --hostname pg-teach-01 \
  --create-boot-disk size=10G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt

sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt-get update
sudo apt-get install postgresql-15-auto-failover
sudo su postgres -c 'pg_dropcluster 15 main --stop'
```


Инициализаруем каталог для мастера
```
sudo su - postgres
export PATH="$PATH:/usr/lib/postgresql/15/bin/"

postgres@pg-teach-01:/root$ pg_autoctl create postgres --pgdata /var/lib/postgresql/data --pgport 5432 --hostname $(hostname -I) --auth trust --no-ssl  --pgctl `which pg_ctl` --monitor postgres://autoctl_node@10.128.0.29:6000/pg_auto_failover -v

15:23:31 7368 WARN  No encryption is used for network traffic! This allows an attacker on the network to read all replication data.
15:23:31 7368 WARN  Using --ssl-self-signed instead of --no-ssl is recommend to achieve more security with the same ease of deployment.
15:23:31 7368 WARN  See https://www.postgresql.org/docs/current/libpq-ssl.html for details on how to improve
15:23:31 7368 INFO  Using default --ssl-mode "prefer"
15:23:31 7368 INFO  Started pg_autoctl postgres service with pid 7370
15:23:31 7370 INFO   /usr/bin/pg_autoctl do service postgres --pgdata /var/lib/postgresql/data -v
15:23:31 7368 INFO  Started pg_autoctl node-init service with pid 7371
15:23:31 7371 INFO  Registered node 1 "node_1" (10.128.0.8:5432) in formation "default", group 0, state "single"
15:23:31 7371 INFO  Writing keeper state file at "/var/lib/postgresql/.local/share/pg_autoctl/var/lib/postgresql/data/pg_autoctl.state"
15:23:31 7371 INFO  Writing keeper init state file at "/var/lib/postgresql/.local/share/pg_autoctl/var/lib/postgresql/data/pg_autoctl.init"
15:23:31 7371 INFO  Successfully registered as "single" to the monitor.
15:23:31 7371 INFO  FSM transition from "init" to "single": Start as a single node
15:23:31 7371 INFO  Initialising postgres as a primary
15:23:31 7371 INFO  Initialising a PostgreSQL cluster at "/var/lib/postgresql/data"
15:23:31 7371 INFO  /usr/lib/postgresql/15/bin//pg_ctl initdb -s -D /var/lib/postgresql/data --option '--auth=trust'
15:23:34 7371 WARN  could not change directory to "/root": Permission denied
15:23:34 7395 INFO   /usr/lib/postgresql/15/bin/postgres -D /var/lib/postgresql/data -p 5432 -h *
15:23:34 7371 INFO  The user "postgres" already exists, skipping.
15:23:34 7371 INFO  CREATE DATABASE postgres;
15:23:34 7371 INFO  The database "postgres" already exists, skipping.
15:23:34 7371 INFO  CREATE EXTENSION pg_stat_statements;
15:23:34 7371 INFO  Disabling synchronous replication
15:23:34 7371 INFO  Reloading Postgres configuration and HBA rules
15:23:34 7370 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/data" on port 5432 with pid 7395
15:23:34 7371 WARN  Failed to resolve hostname "pg-mon" to an IP address that resolves back to the hostname on a reverse DNS lookup.
15:23:34 7371 WARN  Postgres might deny connection attempts from "pg-mon", even with the new HBA rules.
15:23:34 7371 WARN  Hint: correct setup of HBA with host names requires proper reverse DNS setup. You might want to use IP addresses.
15:23:34 7371 WARN  Using IP address "10.128.0.29" in HBA file instead of hostname "pg-mon"
15:23:34 7371 INFO  Reloading Postgres configuration and HBA rules
15:23:34 7371 INFO  Transition complete: current state is now "single"
15:23:34 7371 INFO  keeper has been successfully initialized.
15:23:35 7368 WARN  pg_autoctl service node-init exited with exit status 0
15:23:35 7370 INFO  Postgres controller service received signal SIGTERM, terminating
15:23:35 7370 INFO  Stopping pg_autoctl postgres service
15:23:35 7370 INFO  /usr/lib/postgresql/15/bin//pg_ctl --pgdata /var/lib/postgresql/data --wait stop --mode fast
15:23:35 7368 INFO  Waiting for subprocesses to terminate.
15:23:35 7368 INFO  Stop pg_autoctl
```

Смотрим настройки для сервиса и заводим его  
```
pg_autoctl -q show systemd --pgdata "/var/lib/postgresql/data"

postgres@pg-teach-01:/root$ pg_autoctl -q show systemd --pgdata "/var/lib/postgresql/data"
[Unit]
Description = pg_auto_failover

[Service]
WorkingDirectory = /var/lib/postgresql
Environment = 'PGDATA=/var/lib/postgresql/data'
User = postgres
ExecStart = /usr/bin/pg_autoctl run
Restart = always
StartLimitBurst = 0
ExecReload = /usr/bin/pg_autoctl reload

[Install]
WantedBy = multi-user.target

----

echo "[Unit]
 Description = pg_auto_failover

 [Service]
 WorkingDirectory = /var/lib/postgresql
 Environment = 'PGDATA=/var/lib/postgresql/data'
 User = postgres
 ExecStart = /usr/bin/pg_autoctl run
 Restart = always
 StartLimitBurst = 0
 ExecReload = /usr/bin/pg_autoctl reload

 [Install]
 WantedBy = multi-user.target" |
tee /etc/systemd/system/pgautofailover.service

```

Добавляем доступы
```
echo 'host    replication     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/data/pg_hba.conf
echo 'host    all     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/data/pg_hba.conf
```

Включаем сервис
```
systemctl daemon-reload
systemctl enable pgautofailover
systemctl restart pgautofailover
```



#### Создаём ноду для реплики pg-teach-02
```
yc compute instance create \
  --name pg-teach-02 \
  --hostname pg-teach-02 \
  --create-boot-disk size=10G,type=network-ssd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```

Устанавливаем pg-autofailover
```
sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
sudo apt-get update
sudo apt-get install postgresql-15-auto-failover
sudo su postgres -c 'pg_dropcluster 15 main --stop'
```

Инициализируем реплику
```
postgres@pg-teach-02:~$ pg_autoctl create postgres --pgdata /var/lib/postgresql/data --pgport 5432 --hostname $(hostname -I) --auth trust --no-ssl  --pgctl `which pg_ctl` --monitor postgres://autoctl_node@10.128.0.29:6000/pg_auto_failover -v

16:22:33 4947 WARN  No encryption is used for network traffic! This allows an attacker on the network to read all replication data.
16:22:33 4947 WARN  Using --ssl-self-signed instead of --no-ssl is recommend to achieve more security with the same ease of deployment.
16:22:33 4947 WARN  See https://www.postgresql.org/docs/current/libpq-ssl.html for details on how to improve
16:22:33 4947 INFO  Using default --ssl-mode "prefer"
16:22:33 4947 INFO  Started pg_autoctl postgres service with pid 4949
16:22:33 4949 INFO   /usr/bin/pg_autoctl do service postgres --pgdata /var/lib/postgresql/data -v
16:22:33 4947 INFO  Started pg_autoctl node-init service with pid 4950
16:22:33 4950 INFO  Registered node 2 "node_2" (10.128.0.27:5432) in formation "default", group 0, state "wait_standby"
16:22:33 4950 INFO  Writing keeper state file at "/var/lib/postgresql/.local/share/pg_autoctl/var/lib/postgresql/data/pg_autoctl.state"
16:22:33 4950 INFO  Writing keeper init state file at "/var/lib/postgresql/.local/share/pg_autoctl/var/lib/postgresql/data/pg_autoctl.init"
16:22:33 4950 INFO  Successfully registered as "wait_standby" to the monitor.
16:22:33 4950 INFO  FSM transition from "init" to "wait_standby": Start following a primary
16:22:33 4950 INFO  Transition complete: current state is now "wait_standby"
16:22:33 4950 INFO  New state for node 1 "node_1" (10.128.0.8:5432): single ➜ wait_primary
16:22:33 4950 INFO  New state for node 1 "node_1" (10.128.0.8:5432): wait_primary ➜ wait_primary
16:22:33 4950 INFO  FSM transition from "wait_standby" to "catchingup": The primary is now ready to accept a standby
16:22:33 4950 INFO  Initialising PostgreSQL as a hot standby
16:22:33 4950 INFO   /usr/lib/postgresql/15/bin/pg_basebackup -w -d 'application_name=pgautofailover_standby_2 host=10.128.0.8 port=5432 user=pgautofailover_replicator sslmode=prefer' --pgdata /var/lib/postgresql/backup/node_2 -U pgautofailover_replicator --verbose --progress --max-rate 100M --wal-method=stream --slot pgautofailover_standby_2
16:22:33 4950 INFO  pg_basebackup: initiating base backup, waiting for checkpoint to complete
16:22:34 4950 INFO  pg_basebackup: checkpoint completed
16:22:34 4950 INFO  pg_basebackup: write-ahead log start point: 0/2000028 on timeline 1
16:22:34 4950 INFO  pg_basebackup: starting background WAL receiver
16:22:34 4950 INFO  23146/23146 kB (100%), 0/1 tablespace (.../backup/node_2/global/pg_control)
16:22:35 4950 INFO  23146/23146 kB (100%), 1/1 tablespace
16:22:35 4950 INFO  pg_basebackup: write-ahead log end point: 0/2000138
16:22:35 4950 INFO  pg_basebackup: waiting for background process to finish streaming ...
16:22:35 4950 INFO  pg_basebackup: syncing data to disk ...
16:22:38 4950 INFO  pg_basebackup: renaming backup_manifest.tmp to backup_manifest
16:22:38 4950 INFO  pg_basebackup: base backup completed
16:22:38 4950 INFO  Creating the standby signal file at "/var/lib/postgresql/data/standby.signal", and replication setup at "/var/lib/postgresql/data/postgresql-auto-failover-standby.conf"
16:22:38 4950 INFO  Contents of "/var/lib/postgresql/data/postgresql-auto-failover.conf" have changed, overwriting
16:22:38 4957 INFO   /usr/lib/postgresql/15/bin/postgres -D /var/lib/postgresql/data -p 5432 -h *
16:22:38 4950 INFO  PostgreSQL started on port 5432
16:22:38 4949 INFO  Postgres is now serving PGDATA "/var/lib/postgresql/data" on port 5432 with pid 4957
16:22:38 4950 INFO  Fetched current list of 1 other nodes from the monitor to update HBA rules, including 1 changes.
16:22:38 4950 INFO  Ensuring HBA rules for node 1 "node_1" (10.128.0.8:5432)
16:22:38 4950 INFO  Adding HBA rule: host replication "pgautofailover_replicator" 10.128.0.8/32 trust
16:22:38 4950 INFO  Adding HBA rule: host "postgres" "pgautofailover_replicator" 10.128.0.8/32 trust
16:22:38 4950 INFO  Writing new HBA rules in "/var/lib/postgresql/data/pg_hba.conf"
16:22:38 4950 INFO  Reloading Postgres configuration and HBA rules
16:22:38 4950 INFO  Transition complete: current state is now "catchingup"
16:22:38 4950 INFO  keeper has been successfully initialized.
16:22:38 4947 WARN  pg_autoctl service node-init exited with exit status 0
16:22:38 4949 INFO  Postgres controller service received signal SIGTERM, terminating
16:22:38 4949 INFO  Stopping pg_autoctl postgres service
16:22:38 4949 INFO  /usr/lib/postgresql/15/bin//pg_ctl --pgdata /var/lib/postgresql/data --wait stop --mode fast
16:22:38 4947 INFO  Stop pg_autoctl
```

Аналогично заводим сервис и доступы
```

echo "[Unit]
 Description = pg_auto_failover

 [Service]
 WorkingDirectory = /var/lib/postgresql
 Environment = 'PGDATA=/var/lib/postgresql/data'
 User = postgres
 ExecStart = /usr/bin/pg_autoctl run
 Restart = always
 StartLimitBurst = 0
 ExecReload = /usr/bin/pg_autoctl reload

 [Install]
 WantedBy = multi-user.target" |
tee /etc/systemd/system/pgautofailover.service
--
echo 'host    replication     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/data/pg_hba.conf
echo 'host    all     all              10.128.0.0/24            trust' >>  /var/lib/postgresql/data/pg_hba.conf
--
systemctl daemon-reload
systemctl enable pgautofailover
systemctl restart pgautofailover
```


#### Проверяем работу кластера

Статус нод
```

postgres@pg-mon:~$ pg_autoctl show state --pgdata ./monitor
  Name |  Node |        Host:Port |       TLI: LSN |   Connection |      Reported State |      Assigned State
-------+-------+------------------+----------------+--------------+---------------------+--------------------
node_1 |     1 |  10.128.0.8:5432 |   1: 0/3000148 |   read-write |             primary |             primary
node_2 |     2 | 10.128.0.27:5432 |   1: 0/3000148 |    read-only |           secondary |           secondary
```

Статус репликации
```
postgres@pg-mon:~$ pg_autoctl get formation settings --pgdata ./monitor
  Context |    Name |                   Setting | Value
----------+---------+---------------------------+-----------------------------------
formation | default |      number_sync_standbys | 0
  primary |  node_1 | synchronous_standby_names | 'ANY 1 (pgautofailover_standby_2)'
     node |  node_1 |        candidate priority | 50
     node |  node_2 |        candidate priority | 50
     node |  node_1 |        replication quorum | true
     node |  node_2 |        replication quorum | true
```


Смотрим uri сервиса
```
postgres@pg-mon:~$ pg_autoctl show uri --pgdata ./monitor
        Type |    Name | Connection String
-------------+---------+-------------------------------
     monitor | monitor | postgres://autoctl_node@10.128.0.29:6000/pg_auto_failover?sslmode=prefer
   formation | default | postgres://10.128.0.27:5432,10.128.0.8:5432/postgres?target_session_attrs=read-write&sslmode=prefer
```


Коннектимся и проверяем работу
```
postgres@pg-mon:~$ psql 'postgres://10.128.0.27:5432,10.128.0.8:5432/postgres?target_session_attrs=read-write&sslmode=prefer'

CREATE TABLE companies
(
  id         bigserial PRIMARY KEY,
  name       text NOT NULL,
  image_url  text,
  created_at timestamp without time zone NOT NULL,
  updated_at timestamp without time zone NOT NULL
);

\copy companies from program 'curl -o- https://examples.citusdata.com/mt_ref_arch/companies.csv' with csv
```

Проверяем чтение со слейва
```
postgres@pg-mon:~$ psql 'postgres://10.128.0.27:5432,10.128.0.8:5432/postgres?target_session_attrs=read-only&sslmode=prefer'
psql (15.4 (Ubuntu 15.4-2.pgdg22.04+1))
Type "help" for help.

postgres=# select * from companies;
postgres=# select count(*) from companies;
 count
-------
    57
```


Проверяем свитчовер
```
postgres@pg-mon:~$ pg_autoctl perform switchover --pgdata ./monitor

16:40:36 30009 INFO  Waiting 60 secs for a notification with state "primary" in formation "default" and group 0
16:40:36 30009 INFO  Listening monitor notifications about state changes in formation "default" and group 0
16:40:36 30009 INFO  Following table displays times when notifications are received
    Time |   Name |  Node |        Host:Port |       Current State |      Assigned State
---------+--------+-------+------------------+---------------------+--------------------
16:40:36 | node_1 |     1 |  10.128.0.8:5432 |             primary |            draining
16:40:36 | node_2 |     2 | 10.128.0.27:5432 |           secondary |   prepare_promotion
16:40:36 | node_2 |     2 | 10.128.0.27:5432 |   prepare_promotion |   prepare_promotion
16:40:36 | node_2 |     2 | 10.128.0.27:5432 |   prepare_promotion |    stop_replication
16:40:36 | node_1 |     1 |  10.128.0.8:5432 |             primary |      demote_timeout
16:40:36 | node_1 |     1 |  10.128.0.8:5432 |      demote_timeout |      demote_timeout
16:40:37 | node_2 |     2 | 10.128.0.27:5432 |    stop_replication |    stop_replication
16:40:37 | node_2 |     2 | 10.128.0.27:5432 |    stop_replication |        wait_primary
16:40:37 | node_1 |     1 |  10.128.0.8:5432 |      demote_timeout |             demoted
16:40:37 | node_1 |     1 |  10.128.0.8:5432 |             demoted |             demoted
16:40:37 | node_2 |     2 | 10.128.0.27:5432 |        wait_primary |        wait_primary
16:40:37 | node_1 |     1 |  10.128.0.8:5432 |             demoted |          catchingup
16:40:41 | node_1 |     1 |  10.128.0.8:5432 |          catchingup |          catchingup
16:40:42 | node_1 |     1 |  10.128.0.8:5432 |          catchingup |           secondary
16:40:42 | node_1 |     1 |  10.128.0.8:5432 |           secondary |           secondary
16:40:42 | node_2 |     2 | 10.128.0.27:5432 |        wait_primary |             primary
16:40:42 | node_1 |     1 |  10.128.0.8:5432 |           secondary |           secondary
16:40:42 | node_1 |     1 |  10.128.0.8:5432 |           secondary |           secondary
16:40:42 | node_2 |     2 | 10.128.0.27:5432 |             primary |             primary


postgres@pg-mon:~$ pg_autoctl show state --pgdata ./monitor
  Name |  Node |        Host:Port |       TLI: LSN |   Connection |      Reported State |      Assigned State
-------+-------+------------------+----------------+--------------+---------------------+--------------------
node_1 |     1 |  10.128.0.8:5432 |   2: 0/303E158 |    read-only |           secondary |           secondary
node_2 |     2 | 10.128.0.27:5432 |   2: 0/303E158 |   read-write |             primary |             primary
```

---

### Задание повышенной сложности*
Создать два кластера GKE в разных регионах  
Установить на первом Patroni HA кластер  
Установить на втором Patroni Standby кластер  
Настроить TCP LB между регионами  
Сделать в каждом регионе по клиентской ВМ  
Проверить как ходит трафик с клиентской ВМ  
Описать что и как делали и с какими проблемами столкнулись 


Создаём ВМ etcd в ZONE-A  
```

yc compute instance create \
  --name etcd-01 \
  --hostname etcd-01 \
  --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```


Настраиваем кластер etcd в ZONE-A
```
-- Устанавливаем etcd из пакетов и стопаем сервис  
ssh ubuntu@51.250.64.207 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd && sudo systemctl stop etcd && sudo systemctl stop etcd'

--Копируем конфиг etcd на ноды
ssh ubuntu@51.250.64.207 'sudo tee /etc/default/etcd << END
ETCD_NAME="$(hostname)"
ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
ETCD_ADVERTISE_CLIENT_URLS="http://$(hostname):2379"
ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://$(hostname):2380"
ETCD_INITIAL_CLUSTER_TOKEN="PatroniCluster"
ETCD_INITIAL_CLUSTER="etcd-01=http://etcd-01:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_DATA_DIR="/var/lib/etcd"
END'

-- Стартуем кластер и enable демона etcd
ssh ubuntu@51.250.64.207 'sudo systemctl start etcd'
ssh ubuntu@51.250.64.207 'sudo systemctl enable etcd'


--Проверяем статус кластера etcd

aslepov@aslepov-unix:~/Рабочий стол$ ssh ubuntu@51.250.64.207 'etcdctl cluster-health'
member 4e2079d9addd66f0 is healthy: got healthy result from http://etcd-01:2379
cluster is healthy
```

Разворачиваем postgres из 2х нод в ZONE-A

```

for i in {1..2}; do
yc compute instance create \
  --name pg-teach-0$i \
  --hostname pg-teach-0$i \
  --create-boot-disk size=15G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 4G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
done

```

Настраиваем ноды postgres/patroni  
[Шаблон для конфига patroni.yml](https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni.yml) 
```

--Ставим на них postgres-15
for i in {'158.160.124.39','158.160.54.171'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-15'
done

--Стопаем текущий постгес и удаляем кластера с нод
for i in {'158.160.124.39','158.160.54.171'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo -u postgres pg_ctlcluster 15 main stop && sudo -u postgres pg_dropcluster 15 main '
done


--Ставим пакеты питона

for i in {'158.160.124.39','158.160.54.171'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo apt install -y python3-pip libpq-dev python3-dev python3-psycopg2'
done

--Ставим патрони

for i in {'158.160.124.39','158.160.54.171'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo pip3 install  psycopg2-binary patroni[etcd]'
done

-- Скачиваем конфиги для сервиса и самого патрони
-- На нодах подставляем хостнейм и ip внутренней сети в соответствующие места

for i in {'158.160.124.39','158.160.54.171'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni.service -O "/etc/systemd/system/patroni.service"'
ssh ubuntu@$i 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni.yml -O "/etc/patroni.yml"'
ssh ubuntu@$i 'curr_host=$(hostname -I| sed "s/[ \t]*$//g") && sudo sed "s/SED_CURRENT_ADDRESS/$curr_host/g" -i /etc/patroni.yml'
ssh ubuntu@$i 'sudo sed "s/SED_CURRENT_HOSTNAME/$(hostname)/g" -i /etc/patroni.yml'
ssh ubuntu@$i 'sudo systemctl daemon-reload && sudo systemctl enable patroni'
done

-- Запускаем патрони последовательно на нодах,, смотрим статус кластера
root@pg-teach-01:~# patronictl -c /etc/patroni.yml list
+ Cluster: pgteachcluster (7294227052041464332) --+----+-----------+
| Member      | Host        | Role    | State     | TL | Lag in MB |
+-------------+-------------+---------+-----------+----+-----------+
| pg-teach-01 | 10.128.0.11 | Leader  | running   |  1 |           |
| pg-teach-02 | 10.128.0.35 | Replica | streaming |  1 |         0 |
+-------------+-------------+---------+-----------+----+-----------+
```

Создаём инстанс для haproxy в ZONE-A  
```
yc compute instance create \
  --name pg-lb-01 \
  --hostname pg-lb-01 \
  --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-a,nat-ip-version=ipv4 \
  --zone ru-central1-a \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```


Устанавливаем haproxy на pg-lb-01 в ZONE-A
```
apt update && sudo apt upgrade -y && sudo apt install -y haproxy postgresql-client
```

Настраиваем /etc/haproxy/haproxy.conf
```
global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http


# бэкэнд хапрокси для подключения к мастеру ZONE-A
listen postgres_main_master
    bind *:3300
    mode            tcp
    option httpchk
    http-check connect
    http-check send meth GET uri /master
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg-teach-01 10.128.0.11:5432 check port 8008
    server pg-teach-02 10.128.0.35:5432 check port 8008

# общий cluster-wide балансировщик для мастера
listen postgres_geo_master
    bind *:3333
    mode            tcp
    option httpchk
    http-check connect
    http-check send meth GET uri /master
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg-teach-01 10.128.0.11:5432 check port 8008
    server pg-teach-02 10.128.0.35:5432 check port 8008
    server pg-standby-01 10.128.0.26:5432 check port 8008
    server pg-standby-02 10.128.0.5:5432 check port 8008
```


Создаём на мастере слот репликации
```
postgres=# select pg_create_physical_replication_slot('geo_01');
 pg_create_physical_replication_slot
-------------------------------------
 (geo_01,)
(1 row)

postgres=# select * from pg_replication_slots;
  slot_name  | plugin | slot_type | datoid | database | temporary | active | active_pid | xmin | catalog_xmin | restart_lsn | confirmed_flush_lsn | wal_status | safe_wal_size | two_phase
-------------+--------+-----------+--------+----------+-----------+--------+------------+------+--------------+-------------+---------------------+------------+---------------+-----------
 pg_teach_02 |        | physical  |        |          | f         | t      |      19023 |      |              | 0/345CB60   |                     | reserved   |               | f
 geo_01      |        | physical  |        |          | f         | f      |            |      |              |             |                     |            |               | f
```


Создаём etcd в ZONE-B
```
yc compute instance create \
  --name etcd-02 \
  --hostname etcd-02 \
  --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-b,nat-ip-version=ipv4 \
  --zone ru-central1-b \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```

Настраиваем etcd в zone-b
```
-- Устанавливаем etcd из пакетов и стопаем сервис
ssh ubuntu@158.160.23.241 'sudo apt update && sudo apt upgrade -y && sudo apt install -y etcd && sudo systemctl stop etcd && sudo systemctl stop etcd'

-- Копируем конфиг etcd на ноды
ssh ubuntu@158.160.23.241 'sudo tee /etc/default/etcd << END
ETCD_NAME="$(hostname)"
ETCD_LISTEN_CLIENT_URLS="http://0.0.0.0:2379"
ETCD_ADVERTISE_CLIENT_URLS="http://$(hostname):2379"
ETCD_LISTEN_PEER_URLS="http://0.0.0.0:2380"
ETCD_INITIAL_ADVERTISE_PEER_URLS="http://$(hostname):2380"
ETCD_INITIAL_CLUSTER_TOKEN="PatroniCluster"
ETCD_INITIAL_CLUSTER="etcd-02=http://etcd-02:2380"
ETCD_INITIAL_CLUSTER_STATE="new"
ETCD_DATA_DIR="/var/lib/etcd"
END'

-- Стартуем кластер и enable демона etcd
ssh ubuntu@158.160.23.241 'sudo systemctl start etcd'
ssh ubuntu@158.160.23.241 'sudo systemctl enable etcd'

-- Проверяем статус кластера etcd

ssh ubuntu@158.160.23.241 'etcdctl cluster-health'
member 3e78f89a3c845269 is healthy: got healthy result from http://etcd-02:2379
cluster is healthy
```

Разворачиваем ноды под postgres
```
for i in {1..2}; do
yc compute instance create \
  --name pg-standby-0$i \
  --hostname pg-standby-0$i \
  --create-boot-disk size=15G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 4G \
  --network-interface subnet-name=default-ru-central1-b,nat-ip-version=ipv4 \
  --zone ru-central1-b \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
done
```

Ставим на ноды postgres/patroni
```
-- Ставим на них postgres-15
for i in {'158.160.118.150','158.160.122.128'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo apt update && sudo apt upgrade -y -q && echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" | sudo tee -a /etc/apt/sources.list.d/pgdg.list && wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && sudo apt-get update && sudo apt -y install postgresql-15'
done

-- Стопаем текущий постгес и удаляем кластера с нод
for i in {'158.160.118.150','158.160.122.128'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo -u postgres pg_ctlcluster 15 main stop && sudo -u postgres pg_dropcluster 15 main '
done


-- Ставим пакеты питона
for i in {'158.160.118.150','158.160.122.128'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo apt install -y python3-pip libpq-dev python3-dev python3-psycopg2'
done

-- Ставим патрони
for i in {'158.160.118.150','158.160.122.128'}; do
ssh ubuntu@$i 'echo $(hostname)'
ssh ubuntu@$i 'sudo pip3 install  psycopg2-binary patroni[etcd]'
done
```

Настраиваем [конфиг для Standby Leader](https://github.com/aoslepov/pg-teach-adv/blob/main/lesson11/dz-files/patroni-standby.yml)

```

-- комментарии к patroni.yml
scope: standby # устанавливаем новое имя кластера
namespace: /cluster-standby/ # устанавливаем отдельный немспейс
bootstrap:
    dcs:
#подключаемся к мастеру в ZONE-A через балансировщик
        standby_cluster:
            host: pg-lb-01
            port: 3300
            primary_slot_name: geo_01
            create_replica_methods:
            - basebackup

ssh ubuntu@158.160.118.150 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni.service -O "/etc/systemd/system/patroni.service"'
ssh ubuntu@158.160.118.150 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni-standby.yml -O "/etc/patroni.yml"'
ssh ubuntu@158.160.118.150 'curr_host=$(hostname -I| sed "s/[ \t]*$//g") && sudo sed "s/SED_CURRENT_ADDRESS/$curr_host/g" -i /etc/patroni.yml'
ssh ubuntu@158.160.118.150 'sudo sed "s/SED_CURRENT_HOSTNAME/$(hostname)/g" -i /etc/patroni.yml'
ssh ubuntu@158.160.118.150 'sudo systemctl daemon-reload && sudo systemctl enable patroni'
```


Стартуем патрони на стендбай лидере
```
Oct 26 13:56:26 pg-standby-01 patroni[19169]: 2023-10-26 13:56:26,776 INFO: no action. I am (pg-standby-01), the standby leader with the lock
Oct 26 13:56:16 pg-standby-01 patroni[19169]: 2023-10-26 13:56:16,834 INFO: initialized a new cluster
Oct 26 13:56:16 pg-standby-01 patroni[19169]: 2023-10-26 13:56:16,613 INFO: establishing a new patroni heartbeat connection to postgres
Oct 26 13:56:16 pg-standby-01 patroni[19169]: 2023-10-26 13:56:16,613 WARNING: Could not activate Linux watchdog device: Can't open watchdog device: [Errno 2] No such file or directory: '/dev/watchdog'
Oct 26 13:56:16 pg-standby-01 patroni[19225]: 10.128.0.26:5432 - accepting connections
Oct 26 13:56:16 pg-standby-01 patroni[19223]: 10.128.0.26:5432 - accepting connections
Oct 26 13:56:15 pg-standby-01 patroni[19222]: 2023-10-26 13:56:15.821 UTC [19222] LOG:  started streaming WAL from primary at 0/7000000 on timeline 1
Oct 26 13:56:15 pg-standby-01 patroni[19217]: 2023-10-26 13:56:15.778 UTC [19217] LOG:  database system is ready to accept read-only connections
Oct 26 13:56:15 pg-standby-01 patroni[19221]: 2023-10-26 13:56:15.777 UTC [19221] LOG:  consistent recovery state reached at 0/6000100
Oct 26 13:56:15 pg-standby-01 patroni[19221]: 2023-10-26 13:56:15.761 UTC [19221] LOG:  redo starts at 0/6000028
Oct 26 13:56:15 pg-standby-01 patroni[19221]: 2023-10-26 13:56:15.723 UTC [19221] LOG:  entering standby mode
Oct 26 13:56:15 pg-standby-01 patroni[19221]: 2023-10-26 13:56:15.696 UTC [19221] LOG:  database system was interrupted; last known up at 2023-10-26 13:56:13 UTC
Oct 26 13:56:15 pg-standby-01 patroni[19217]: 2023-10-26 13:56:15.653 UTC [19217] LOG:  listening on Unix socket "./.s.PGSQL.5432"
Oct 26 13:56:15 pg-standby-01 patroni[19217]: 2023-10-26 13:56:15.634 UTC [19217] LOG:  listening on IPv4 address "10.128.0.26", port 5432
Oct 26 13:56:15 pg-standby-01 patroni[19217]: 2023-10-26 13:56:15.634 UTC [19217] LOG:  starting PostgreSQL 15.4 (Ubuntu 15.4-2.pgdg22.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04>
Oct 26 13:56:15 pg-standby-01 patroni[19218]: 10.128.0.26:5432 - no response
Oct 26 13:56:15 pg-standby-01 patroni[19169]: 2023-10-26 13:56:15,587 INFO: postmaster pid=19217
Oct 26 13:56:14 pg-standby-01 patroni[19169]: 2023-10-26 13:56:14,846 INFO: bootstrapped clone from remote member postgresql://pg-lb-01:3300
Oct 26 13:56:14 pg-standby-01 patroni[19169]: 2023-10-26 13:56:14,845 INFO: replica has been created using basebackup
Oct 26 13:56:13 pg-standby-01 patroni[19176]: WARNING:  skipping special file "./.s.PGSQL.5432"
Oct 26 13:56:13 pg-standby-01 patroni[19176]: WARNING:  skipping special file "./.s.PGSQL.5432"
Oct 26 13:56:12 pg-standby-01 patroni[19169]: 2023-10-26 13:56:12,946 INFO: trying to bootstrap a new standby leader
Oct 26 13:56:12 pg-standby-01 patroni[19169]: 2023-10-26 13:56:12,842 INFO: Lock owner: None; I am pg-standby-01
Oct 26 13:56:12 pg-standby-01 patroni[19169]: 2023-10-26 13:56:12,786 INFO: No PostgreSQL configuration items changed, nothing to reload.
Oct 26 13:56:12 pg-standby-01 patroni[19169]: 2023-10-26 13:56:12,730 INFO: Selected new etcd server http://etcd-02:2379
Oct 26 13:56:12 pg-standby-01 systemd[1]: Started Runners to orchestrate a high-availability PostgreSQL.

-- топология кластера ZONE-A
root@pg-teach-01:~# patronictl -c /etc/patroni.yml topology
+ Cluster: pgteachcluster (7294227052041464332) ----+----+-----------+
| Member        | Host        | Role    | State     | TL | Lag in MB |
+---------------+-------------+---------+-----------+----+-----------+
| pg-teach-01   | 10.128.0.11 | Leader  | running   |  1 |           |
| + pg-teach-02 | 10.128.0.35 | Replica | streaming |  1 |         0 |
+---------------+-------------+---------+-----------+----+-----------+

-- топология кластера ZONE-B
root@pg-standby-01:/etc# patronictl -c /etc/patroni.yml topology
+ Cluster: standby (7294227052041464332) ------+-----------+----+-----------+
| Member        | Host        | Role           | State     | TL | Lag in MB |
+---------------+-------------+----------------+-----------+----+-----------+
| pg-standby-01 | 10.128.0.26 | Standby Leader | streaming |  1 |           |
+---------------+-------------+----------------+-----------+----+-----------+
```

Проверяем репликацию на стендбай кластер 
```
root@pg-teach-01:~# psql -h 10.128.0.11 -U postgres 
create database otus;
\c otus
create table test(i int);
otus=# insert into test values (1),(2),(3);

root@pg-standby-01:/etc# psql -h 10.128.0.26 -U postgres -d otus
Password for user postgres:
psql (15.4 (Ubuntu 15.4-2.pgdg22.04+1))
Type "help" for help.

otus=# select * from test;
 i
---
 1
 2
 3
(3 rows)
```

Добавляем [конфиг на реплику](https://github.com/aoslepov/pg-teach-adv/blob/main/lesson11/dz-files/patroni-standby-replica.yml) на стендбай-кластер в ZONE-B
```
-- комментарии к patroni.yml
scope: standby # устанавливаем новое имя кластера
namespace: /cluster-standby/ # устанавливаем отдельный немспейс


ssh ubuntu@158.160.122.128 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni.service -O "/etc/systemd/system/patroni.service"'
ssh ubuntu@158.160.122.128 'sudo wget https://raw.githubusercontent.com/aoslepov/pg-teach-adv/main/lesson11/dz-files/patroni-standby-replica.yml -O "/etc/patroni.yml"'
ssh ubuntu@158.160.122.128 'curr_host=$(hostname -I| sed "s/[ \t]*$//g") && sudo sed "s/SED_CURRENT_ADDRESS/$curr_host/g" -i /etc/patroni.yml'
ssh ubuntu@158.160.122.128 'sudo sed "s/SED_CURRENT_HOSTNAME/$(hostname)/g" -i /etc/patroni.yml'
ssh ubuntu@158.160.122.128 'sudo systemctl daemon-reload && sudo systemctl enable patroni'
```

Стартуем реплику в zone-b
```
Oct 26 14:22:24 pg-standby-02 patroni[8831]: 2023-10-26 14:22:24,680 INFO: no action. I am (pg-standby-02), a secondary, and following a standby leader (pg-standby-01)
Oct 26 14:22:24 pg-standby-02 patroni[8831]: 2023-10-26 14:22:24,519 INFO: establishing a new patroni heartbeat connection to postgres
Oct 26 14:22:24 pg-standby-02 patroni[8831]: 2023-10-26 14:22:24,519 INFO: Lock owner: pg-standby-01; I am pg-standby-02
Oct 26 14:22:24 pg-standby-02 patroni[8888]: 10.128.0.5:5432 - accepting connections
Oct 26 14:22:24 pg-standby-02 patroni[8886]: 10.128.0.5:5432 - accepting connections
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.716 UTC [8883] LOG:  waiting for WAL to become available at 0/7000160
Oct 26 14:22:23 pg-standby-02 patroni[8885]: 2023-10-26 14:22:23.715 UTC [8885] FATAL:  could not start WAL streaming: ERROR:  replication slot "pg_standby_02" does not exist
Oct 26 14:22:23 pg-standby-02 patroni[8884]: 2023-10-26 14:22:23.698 UTC [8884] FATAL:  could not start WAL streaming: ERROR:  replication slot "pg_standby_02" does not exist
Oct 26 14:22:23 pg-standby-02 patroni[8879]: 2023-10-26 14:22:23.671 UTC [8879] LOG:  database system is ready to accept read-only connections
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.671 UTC [8883] LOG:  invalid record length at 0/7000148: wanted 24, got 0
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.671 UTC [8883] LOG:  consistent recovery state reached at 0/7000148
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.664 UTC [8883] LOG:  redo starts at 0/7000060
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.645 UTC [8883] LOG:  entering standby mode
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.622 UTC [8883] HINT:  If this has occurred more than once some data might be corrupted and you might need to choose an earlier recovery target.
Oct 26 14:22:23 pg-standby-02 patroni[8883]: 2023-10-26 14:22:23.622 UTC [8883] LOG:  database system was interrupted while in recovery at log time 2023-10-26 13:56:43 UTC
Oct 26 14:22:23 pg-standby-02 patroni[8879]: 2023-10-26 14:22:23.602 UTC [8879] LOG:  listening on Unix socket "./.s.PGSQL.5432"
Oct 26 14:22:23 pg-standby-02 patroni[8879]: 2023-10-26 14:22:23.564 UTC [8879] LOG:  listening on IPv4 address "10.128.0.5", port 5432
Oct 26 14:22:23 pg-standby-02 patroni[8879]: 2023-10-26 14:22:23.564 UTC [8879] LOG:  starting PostgreSQL 15.4 (Ubuntu 15.4-2.pgdg22.04+1) on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.4.0-1ubuntu1~22.04) >
Oct 26 14:22:23 pg-standby-02 patroni[8880]: 10.128.0.5:5432 - no response
Oct 26 14:22:23 pg-standby-02 patroni[8831]: 2023-10-26 14:22:23,494 INFO: postmaster pid=8879
Oct 26 14:22:22 pg-standby-02 patroni[8831]: 2023-10-26 14:22:22,826 INFO: bootstrapped from leader 'pg-standby-01'
Oct 26 14:22:22 pg-standby-02 patroni[8831]: 2023-10-26 14:22:22,825 INFO: replica has been created using basebackup
Oct 26 14:22:21 pg-standby-02 patroni[8838]: WARNING:  skipping special file "./.s.PGSQL.5432"
Oct 26 14:22:21 pg-standby-02 patroni[8838]: WARNING:  skipping special file "./.s.PGSQL.5432"
Oct 26 14:22:21 pg-standby-02 patroni[8831]: 2023-10-26 14:22:21,144 INFO: trying to bootstrap from leader 'pg-standby-01'
Oct 26 14:22:21 pg-standby-02 patroni[8831]: 2023-10-26 14:22:21,092 INFO: Lock owner: pg-standby-01; I am pg-standby-02
Oct 26 14:22:21 pg-standby-02 patroni[8831]: 2023-10-26 14:22:21,036 INFO: No PostgreSQL configuration items changed, nothing to reload.
Oct 26 14:22:20 pg-standby-02 patroni[8831]: 2023-10-26 14:22:20,979 INFO: Selected new etcd server http://etcd-02:2379
Oct 26 14:22:20 pg-standby-02 systemd[1]: Started Runners to orchestrate a high-availability PostgreSQL.


patronictl -c /etc/patroni.yml list
+ Cluster: standby (7294227052041464332) ------+-----------+----+-----------+
| Member        | Host        | Role           | State     | TL | Lag in MB |
+---------------+-------------+----------------+-----------+----+-----------+
| pg-standby-01 | 10.128.0.26 | Standby Leader | streaming |  1 |           |
| pg-standby-02 | 10.128.0.5  | Replica        | streaming |  1 |         0 |
+---------------+-------------+----------------+-----------+----+-----------+
```


Проверяем подключение к гео-мастеру через прокси с прокси ZONE-A
```

root@pg-lb-01:~# psql -U postgres -h 127.0.0.1 -p 3333 -d otus
Password for user postgres:

otus=# SELECT inet_server_addr();
 inet_server_addr
------------------
 10.128.0.11
(1 row)

otus=# select * from test;
 i
---
 1
 2
 3
(3 rows)
```


Создаём прокси для ZONE-B

```
yc compute instance create \
  --name pg-lb-02 \
  --hostname pg-lb-02 \
  --create-boot-disk size=10G,type=network-hdd,image-folder-id=standard-images,image-family=ubuntu-2204-lts \
  --cores 2 \
  --memory 2G \
  --network-interface subnet-name=default-ru-central1-b,nat-ip-version=ipv4 \
  --zone ru-central1-b \
  --metadata-from-file ssh-keys=/home/aslepov/meta.txt
```


Устанавливаем хапрокси и настраиваем его
```
apt update && sudo apt upgrade -y && sudo apt install -y haproxy postgresql-client

root@pg-lb-02:~# vim /etc/haproxy/haproxy.cfg
global
	log /dev/log	local0
	log /dev/log	local1 notice
	chroot /var/lib/haproxy
	stats socket /run/haproxy/admin.sock mode 660 level admin expose-fd listeners
	stats timeout 30s
	user haproxy
	group haproxy
	daemon

	# Default SSL material locations
	ca-base /etc/ssl/certs
	crt-base /etc/ssl/private

	# See: https://ssl-config.mozilla.org/#server=haproxy&server-version=2.0.3&config=intermediate
        ssl-default-bind-ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384
        ssl-default-bind-ciphersuites TLS_AES_128_GCM_SHA256:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256
        ssl-default-bind-options ssl-min-ver TLSv1.2 no-tls-tickets

defaults
	log	global
	mode	http
	option	httplog
	option	dontlognull
        timeout connect 5000
        timeout client  50000
        timeout server  50000
	errorfile 400 /etc/haproxy/errors/400.http
	errorfile 403 /etc/haproxy/errors/403.http
	errorfile 408 /etc/haproxy/errors/408.http
	errorfile 500 /etc/haproxy/errors/500.http
	errorfile 502 /etc/haproxy/errors/502.http
	errorfile 503 /etc/haproxy/errors/503.http
	errorfile 504 /etc/haproxy/errors/504.http


listen postgres_standby_master
    bind *:3300
    mode            tcp
    option httpchk
    http-check connect
    http-check send meth GET uri /master
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg-standby-01 10.128.0.26:5432 check port 8008
    server pg-standby-02 10.128.0.5:5432 check port 8008


listen postgres_geo_master
    bind *:3333
    mode            tcp
    option httpchk
    http-check connect
    http-check send meth GET uri /master
    http-check expect status 200
    default-server inter 10s fall 3 rise 3 on-marked-down shutdown-sessions
    server pg-teach-01 10.128.0.11:5432 check port 8008
    server pg-teach-02 10.128.0.35:5432 check port 8008
    server pg-standby-01 10.128.0.26:5432 check port 8008
    server pg-standby-02 10.128.0.5:5432 check port 8008
```

Проверяем коннект к cluster-wide мастеру через прокси в ZONE-B
```
root@pg-lb-02:~# psql -U postgres -h 127.0.0.1 -p 3333 -d otus

otus=# select * from test;
 i
---
 1
 2
 3
(3 rows)

otus=# SELECT inet_server_addr();
 inet_server_addr
------------------
 10.128.0.11
```

Также в yandex cloud можно настроить network balancer:  
* создаём группу для pg-lb-01, pg-lb-02  
* пробрасываем порт 3333 гео-мастера  
* далее можно подключаться на ip балансера и, соотвественно, на гео-мастер  
